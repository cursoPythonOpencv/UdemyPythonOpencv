{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectção de Faces\n",
    "\n",
    "## Classificador de Haar\n",
    "\n",
    "Para detcção de faces usando o classificador de Haar, é preciso calcular as somatórias de muitos diferentes regiões retangulares dentro da imagem. Ao fazer isso o esforço computacional é grande. \n",
    "\n",
    "Para construir um sistema em tempo real, não pode-se gastar tantos ciclos computando essas somas. Então, é usado algo chamado imagens integrais.\n",
    "\n",
    "![alt text](https://www.codeproject.com/KB/audio-video/haar_detection/intimage.png \"Logo Title Text 1\")\n",
    "\n",
    "[logo]: https://www.codeproject.com/KB/audio-video/haar_detection/intimage.png \"Logo Title Text 2\"\n",
    "\n",
    "Para calcular a soma de qualquer retângulo na imagem, não precisa passar por todo o elementos nessa área retangular. Digamos que o AP indique a soma de todos os elementos no retângulo formado pelo ponto superior esquerdo e o ponto P na imagem como os dois diagonalmente cantos opostos. Então, agora, se para calcular a área do retângulo ABCD, pode-se use a seguinte fórmula:\n",
    "\n",
    "$ABCD = AC – (AB + AD - AA)$\n",
    "\n",
    "Por que essa fórmula específica é importante? Como foi discutido na aula anteriormente, ao usar o classificador de Haar e extraír características da imagem, a computação das áreas de um grande número de retângulos na imagem é feita em escalas múltiplas. \n",
    "\n",
    "Muitos desses cálculos são repetitivos e o processo geral é muito lento. Na verdade, é tão lento que não pode-se executar nada em tempo real. Essa é a razão usamos essa formulação! \n",
    "\n",
    "O bom desta abordagem é que não precisa recalcular qualquer instância da imagem. Todos os valores para as áreas do lado direito desta equação já estão disponíveis. Então, é apenas usado para calcular a área de qualquer retângulo novo e extrair os recursos.\n",
    "\n",
    "Importando as bibliotecas e o classficador de Haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos de um modelo de classificador que possa ser usado para detectar os rostos em uma imagem. OpenCV\n",
    "fornece um arquivo xml que pode ser usado para essa finalidade. Nós usamos a função\n",
    "CascadeClassifier para carregar o arquivo xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cassificadores de Haar\n",
    "face_cascade = cv2.CascadeClassifier('C:/opencv/build/etc/haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando começamos a capturar os quadros de entrada da webcam, é convertido os freme em tons de cinza e usa-se a função **detectMultiScale** para obter caixas delimitadoras para todas as faces na imagem atual. \n",
    "\n",
    "FUNÇÃO **detectMultiscale (scalefactor , minNeighbors )**\n",
    "\n",
    "Entrada: \n",
    "        1. scalefactor = Parâmetro que especifica quanto o tamanho da imagem é reduzido em cada escala de imagem.\n",
    "        2. minNeighbors = Parâmetro que especifica quantos vizinhos cada retângulo candidato deve ter para retê-lo. \n",
    "\n",
    "Saída:\n",
    "        1. retângulo com coordenadas (x, y, w, h) ao redor da face detectada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #Inicializa um captura de vídeo com a webcam do pc\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "    cv2.imshow('Face detectada', img)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break;\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
